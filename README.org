#+TITLE: Question Generation with Multi Hop Reasoning
#+AUTHOR: Akshit Kumar, Arjun Dosajh, Hardik Mittal

* Problem Statement
Given some context and an answer, generate questions which involve multi-hop reasoning.

* Experiments
** Recursive RAG

* Using a Knowledge base as context
** MetaQA
We utilized the MetaQA dataset of movies for experimentation.

## Direct Inference Baseline
Datasets used - MusiQue
- We give Llama-3.2 8B the complex question and context and get the response
- We calculate ROUGE score between the response and ground truth answer

### Direct Inference Baseline results

| Dataset | ROUGE-1 F1 | ROUGE-2 F1 | ROUGE-L F1 | Exact Matches | Partial Matches |
|---------|------------|------------|------------|---------------|-----------------|
| Musique | 0.1515 | 0.0816 | 0.1504 | 0.0532 | 0.1831 |


## Recursive RAG Baseline
Datasets used - MusiQue and MetaQA
- We first break the knowledge base into chunks and get embeddings using MiniLM for each chunk and store them in a vector database
- We calculate the embedding for each query and use faiss to get the top-k similar chunks
- The retrieved chunks are used to search for other chunks in the knowledge base and get the top-k' similar chunks. This is done recursively.
- All the retrieved chunks and the complex question are given to Llama-3.2 8B
- We calculate ROUGE score between the response and ground truth answer

### Baseline results
| Model | ROUGE-1 F1 | ROUGE-2 F1 | ROUGE-L F1 | Exact Matches | Partial Matches |
|---------|------------|------------|------------|---------------|-----------------|
| Musique | 0.3047 | 0.1916 | 0.3045 | 0.1791 | 0.3183 |
| MetaQA | 0.2029 | 0.1912 | 0.1782 | 0.1148 | 0.2230 |

** Knowledge graph
- We first converted the knowledge base into a knowledge graph.
- This was done using the ~networkx~ library from python.
- A directed graph was created from movies to other entities like actor, year of release etc.
** Creating hops
Then we wrote three different methods to generate "hops" from this knowledge graph where every "hop" was one single relation pair (movie, entity, relation).
*** Random Neighbour
As the name suggests, this chooses one of the neighbours randomly every time there is a hop, we limit this to 5 hops.
*** Most popular neighbour
This method chooses the neighbour with the highest degree every time.
*** Semantically furthest away neighbour
This method was incorporated to make the dataset more diverse by taking in the longest
relationshiops for generating hops. We use a sentence transformer (minilm) to
generate embeddings for all entities and movies and *always* select the furthest
away entity when we decide to jump.

* Applications and metrics
** Student teacher learning
This method of generating simple reasoning questions to help steer
a smaller LM to reason is a very popular way
to train smaller language models. We utilise the knowledge
graph to ground the smaller LM on the knowledge base
while also helping it learn how to reason about complex questions
from the simpler hops.
